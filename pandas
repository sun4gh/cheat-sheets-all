https://nbviewer.jupyter.org/github/pybokeh/jupyter_notebooks/blob/master/pandas/PandasCheatSheet.ipynb

>>>import pandas as pd
>>>import numpy as np


# CREATING DATAFRAMES

>>>column_keys_list_values_dict = {  "January" : [ 3, 7,9] , "February" : [2,5,6] }

>>>a_df = pd.DataFrame( column_keys_list_values_dict )
>>>a_df
   February  January
0         2        3
1         5        7
2         6        9

>>>a_df = pd.DataFrame( column_keys_list_values_dict , index = ["New York", "New Jersey", "Connecticut"] )
>>> a_df
             February  January
New York            2        3
New Jersey          5        7
Connecticut         6        9

>>> for each in a_df.index:
...     print each
... 
New York
New Jersey
Connecticut

>>> for each in a_df["January"]:
...     print each
... 
3
7
9


>>> type(a_df)
<class 'pandas.core.frame.DataFrame'>

>>> type(a_df["January"])
<class 'pandas.core.series.Series'>

>>> type(a_df.index)
<class 'pandas.core.indexes.base.Index'>

>>> a_df.index          # NOT a_df["index"] which would look for a column named 'index'
Index([u'New York', u'New Jersey', u'Connecticut'], dtype='object')

#define a dataframe by rows - notice the default index, and columns, assigned by pandas
>>> b_df = pd.DataFrame( [ [32,34], [25, 26], [38,39] ])
>>> b_df
    0   1
0  32  34
1  25  26
2  38  39

#define by rows and supply the column labels when defining
>>> b_df = pd.DataFrame( [ [32,34], [25, 26], [38,39] ], columns=["June", "July"] )
>>> b_df
   June  July
0    32    34
1    25    26
2    38    39

#or define by rows and supply column labels and index labels 
>>> b_df = pd.DataFrame( [ [32,34], [25, 26], [38,39] ], columns=["June", "July"], index = a_df.index )
>>> b_df
             June  July
New York       32    34
New Jersey     25    26
Connecticut    38    39

#missing values - avoid ambiguously providing missing values, and instead provide those as np.NaN
>>> b_df = pd.DataFrame( [ [32,34], [25, ], [38,39] ], columns=["June", "July"], index = a_df.index ) 
>>> b_df
             June  July
New York       32  34.0
New Jersey     25   NaN
Connecticut    38  39.0

>>> b_df = pd.DataFrame( [ [32,34], [ , 26 ], [38,39] ], columns=["June", "July"], index = a_df.index )
  File "<stdin>", line 1
    b_df = pd.DataFrame( [ [32,34], [ , 26 ], [38,39] ], columns=["June", "July"], index = a_df.index )
                                      ^
                                      SyntaxError: invalid syntax

>>> b_df = pd.DataFrame( [ [32,34], [NaN , 26 ], [38,39] ], columns=["June", "July"], index = a_df.index )
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
NameError: name 'NaN' is not defined

>>> b_df = pd.DataFrame( [ [32,34], [np.NaN , 26 ], [38,39] ], columns=["June", "July"], index = a_df.index )
>>> b_df
             June  July
New York     32.0    34
New Jersey    NaN    26
Connecticut  38.0    39 

>>> c_df = pd.DataFrame( { "March" : [np.NAN , np.NAN, 8], "August" : [2,np.NAN ,2] }, index = a_df.index)
>>> c_df
             August  March
New York        2.0    NaN
New Jersey      NaN    NaN
Connecticut     2.0    8.0


>>> pd.concat( [a_df, c_df, b_df], axis =1)        # axis is horizontal, the default is 0 which is the vertical axis
             February  January  August  March  June  July
New York            2        3     2.0    NaN  32.0    34
New Jersey          5        7     NaN    NaN   NaN    26
Connecticut         6        9     2.0    8.0  38.0    39

>>> winter_summer = pd.concat( [a_df, c_df, b_df], axis =1)
>>> type(winter_summer)
<class 'pandas.core.frame.DataFrame'>

#ADD ONE MORE ROW
#USE LOC for adding one more row, IF YOU KNOW THE INDEX VALUE you want to use.
#You can also use append and concat, but you have to first create a dataframe out of that, 
#then append or concat, and both produce a NEW object instead of modifying the existing
#object. 
>>> winter_summer.loc["California"] = [ 5,4,3.0,2.0,1,0]
>>> winter_summer
             January  February  March  August  June  July
New York         3.0       2.0    NaN     2.0  32.0  34.0
New Jersey       7.0       5.0    NaN     NaN  25.0  26.0
Connecticut      9.0       6.0    8.0     2.0  38.0  39.0
California       5.0       4.0    3.0     2.0   1.0   0.0

#USING ILOC instead of loc, CANNOT be used to introduce a NEW row.
#It can only be used to replace the values of an existing row.
>>> len(winter_summer)
4
>>> winter_summer.iloc[ 3 ] #this is the last item's integer location (it is California's iloc)
January     5.0
February    4.0
March       3.0
August      2.0
June        1.0
July        0.0
Name: California, dtype: float64
>>> winter_summer.iloc[ 4 ] = [ 5,4,3.0,2.0,1,0]
Traceback (most recent call last):
  File "/anaconda3/lib/python3.7/site-packages/pandas/core/indexing.py", line 2139, in _validate_integer
    raise IndexError("single positional indexer is out-of-bounds")
IndexError: single positional indexer is out-of-bounds
>>> winter_summer.iloc[ 3 ] = [ 12, 12, 12, 12, 12, 12]  # can be used to replace the data for a row
>>> winter_summer
             January  February  March  August  June  July
New York         3.0       2.0    NaN     2.0  32.0  34.0
New Jersey       7.0       5.0    NaN     NaN  25.0  26.0
Connecticut      9.0       6.0    8.0     2.0  38.0  39.0
California      12.0      12.0   12.0    12.0  12.0  12.0

#APPEND can also be used to add one more row if you don't care to 
#maintain the index. (This is useful when the index does not 
#itself carry information but rather acts as a row number.)
>>> winter_summer.append( {"August": 24}, ignore_index= True) 
   January  February  March  August  June  July
0      3.0       2.0    NaN     2.0  32.0  34.0
1      7.0       5.0    NaN     NaN  25.0  26.0
2      9.0       6.0    8.0     2.0  38.0  39.0
3     12.0      12.0   12.0    12.0  12.0  12.0
4      NaN       NaN    NaN    24.0   NaN   NaN
#This returns a NEW dataframe, leaving the other intact.
#The index is lost. You pass in a dictionary with as many of the values
#as you know; the rest are set to NaN. Original dataframe is left intact.
>>> winter_summer
             January  February  March  August  June  July
New York         3.0       2.0    NaN     2.0  32.0  34.0
New Jersey       7.0       5.0    NaN     NaN  25.0  26.0
Connecticut      9.0       6.0    8.0     2.0  38.0  39.0
California      12.0      12.0   12.0    12.0  12.0  12.0

#Instead of a dictionary of key-value pairs, you can also represent the same information
#as a series where the index is the columns of the dataframe you're appending to
#passing in the values as a list.
>>> Illinois_s = pd.Series( [6,5,4,3,2,1], index = winter_summer.columns)
>>> Illinois_s
January     6
February    5
March       4
August      3
June        2
July        1
dtype: int64
>>> winter_summer.append( Illinois_s, ignore_index = True)
   January  February  March  August  June  July
0      3.0       2.0    NaN     2.0  32.0  34.0
1      7.0       5.0    NaN     NaN  25.0  26.0
2      9.0       6.0    8.0     2.0  38.0  39.0
3     12.0      12.0   12.0    12.0  12.0  12.0
4      6.0       5.0    4.0     3.0   2.0   1.0
#But the index is lost again.
#However, if the series is named (name = "Illinois") then we do not need to ignore_index
#and we do not lose the index
>>> Illinois_s = pd.Series( [6,5,4,3,2,1], index = winter_summer.columns, name = "Illinois" )
>>> winter_summer.append( Illinois_s)
             January  February  March  August  June  July
New York         3.0       2.0    NaN     2.0  32.0  34.0
New Jersey       7.0       5.0    NaN     NaN  25.0  26.0
Connecticut      9.0       6.0    8.0     2.0  38.0  39.0
California      12.0      12.0   12.0    12.0  12.0  12.0
Illinois         6.0       5.0    4.0     3.0   2.0   1.0

CONCLUSION ON ADDING ONE NEW ROW:
If the index is a meaningful label, like US States above, then you probably
wouldn't want to add a new row without having a meaningful value for that row's Index, a
value like "Illinois". If you do have such a value, then use "loc" (which modifies the existing
dataframe). You can use a named Series and append() but that creates a new dataframe. 
If you don't have meaningful values in the index, then append might do the trick,
but remember to use ignore_index = True.

Other things to do:
- pass a list of named series to append() , to get them added at once
- at a row from another dataframe to this dataframe
Additional information here: https://thispointer.com/python-pandas-how-to-add-rows-in-a-dataframe-using-dataframe-append-loc-iloc/

#DELETE (drop) ONE ROW
#the below works with unique values
#returns a new object, so need to reassign
>>> winter_summer.drop( [ "California" ], axis = 0 )
             January  February  March  August  June  July
New York         3.0       2.0    NaN     2.0  32.0  34.0
New Jersey       7.0       5.0    NaN     NaN  25.0  26.0
Connecticut      9.0       6.0    8.0     2.0  38.0  39.0
>>> winter_summer
             January  February  March  August  June  July
New York         3.0       2.0    NaN     2.0  32.0  34.0
New Jersey       7.0       5.0    NaN     NaN  25.0  26.0
Connecticut      9.0       6.0    8.0     2.0  38.0  39.0
California       5.0       4.0    3.0     2.0   1.0   0.0
>>> winter_summer = winter_summer.drop( [ "California" ], axis = 0 )
>>> winter_summer
             January  February  March  August  June  July
New York         3.0       2.0    NaN     2.0  32.0  34.0
New Jersey       7.0       5.0    NaN     NaN  25.0  26.0
Connecticut      9.0       6.0    8.0     2.0  38.0  39.0

#SLICING - via integer location - obtaining a cell by using single values for index and column

      Here's what's happened above (cut and paste into interpereter, if needed)`
import pandas as pd
import numpy as np
column_keys_list_values_dict = {  "January" : [ 3, 7,9] , "February" : [2,5,6] }
a_df = pd.DataFrame( column_keys_list_values_dict , index = ["New York", "New Jersey", "Connecticut"] )
b_df = pd.DataFrame( [ [32,34], [25, 26], [38,39] ], columns=["June", "July"], index = a_df.index )
c_df = pd.DataFrame( { "March" : [np.NAN , np.NAN, 8], "August" : [2,np.NAN ,2] }, index = a_df.index)
winter_summer = pd.concat( [a_df, c_df, b_df], axis =1)

# .loc[] slicing by index label and by column label, getting back a single cell

>>> winter_summer.loc["Connecticut", "June"]      #slicing by label, not a function
38.0

# .iloc[] is "Purely integer-location based indexing for selection by position."
>>> winter_summer.iloc[ 0, 1]                     #slicing by integer - 0th row, and 1st column - returns a cell
3

>>> type(winter_summer.iloc[ 0, 1])
<type 'numpy.int64'>                              # a cell


#SLICING - via integer location -  using ranges of index, and/or columns

>>> winter_summer.iloc[ : , 1:2]                  #slicing by integer ranges - returns a DataFrame
             January                              #range 1:2 is January only, becuase 0th is Feb, 1st is Jan, etc.
New York           3
New Jersey         7
Connecticut        9

>>> type(winter_summer.iloc[ : , 1:2])
<class 'pandas.core.frame.DataFrame'>

>>> type(winter_summer.iloc[:, 1:1])               #pass in a range of rows, range of columns, even if it amounts to 1
<class 'pandas.core.frame.DataFrame'>              #you get a dataframe

>>> type(winter_summer.iloc[:, 1])                 #pass in a range of rows, single column, not a range,
<class 'pandas.core.series.Series'>                #you get back a Series


#SLICING: get entire COLUMNS as Dataframes or as Series

>>> extreme_months_list = [ 'February', 'August']
>>> extreme_months_list
['February', 'August']
>>> winter_summer[ extreme_months_list ]            # use the slicing format (square brackets), and pass it a list
             February  August
New York            2     2.0
New Jersey          5     NaN
Connecticut         6     2.0

>>> winter_summer [[ 'January', 'July']]    # or make the list on the go
             January  July
New York           3    34
New Jersey         7    26
Connecticut        9    39

>>> type(winter_summer [[ 'January', 'July']])
<class 'pandas.core.frame.DataFrame'>

>>> winter_summer[['January']]              # likewise, for a list of only one column, you still receive a dataframe 
             January
New York           3
New Jersey         7
Connecticut        9

>>> type(winter_summer[['January']])        # slicing by a list of columns, even a single item list, returns a dataframe
<class 'pandas.core.frame.DataFrame'>

>>> type(winter_summer['January'])          # clice by a single column, not a list, returns a Series, not dataframe
<class 'pandas.core.series.Series'>


## SLICING BY BOOLEAN Series... to filter ROWS

>>> winter_summer[  [True, True, False] ]   # pass a list of booleans equal in size to the index
                                            # to filter out all the columns coresponding to the False
            February  January  August  March  June  July
New York           2        3     2.0    NaN  32.0    34
New Jersey         5        7     NaN    NaN   NaN    26

>>> just_jersey_list = [False, True, False]
>>> just_jersey_list
[False, True, False]
>>> winter_summer[ just_jersey_list ]
            February  January  August  March  June  July
New Jersey         5        7     NaN    NaN    25    26

>>> winter_summer [ extreme_months_list] [ just_jersey_list ]     #chaining subsetting
            February  August
New Jersey         5     NaN



>>> winter_summer [  [True, False] ]        # try to pass a list of booleans unequal to size of index
Traceback (most recent call last):
..
ValueError: Item wrong length 2 instead of 3.


#alternatively : pass in a condition that results in a boolean series, even a complex boolean logic
#to be added here later ***

## GETTING A BOOLEAN SERIES using methods
# np.NAN comparisons are tricky, the method .notna() makes it easier
# it means if it's not np.NAN
>>> winter_summer["June"].notna()           #returns a boolean Series
New York        True
New Jersey     False
Connecticut     True
Name: June, dtype: bool
>>> type(winter_summer["June"].notna())
<class 'pandas.core.series.Series'>


## GETTING A BOOLEAN SERIES using a CONDITION

# Passing a returned boolean series to slicing by T/F index
>>> winter_summer[ winter_summer["June"].notna() ]
             February  January  August  March  June  July
New York            2        3     2.0    NaN  32.0    34
Connecticut         6        9     2.0    8.0  38.0    39

#*** to be filled here... using a_df[ "column'] == 3 etc.


# BOOLEAN DATAFRAMES using the method on the entire dataframe

>>> winter_summer.notna()
             February  January  August  March   June  July
New York         True     True    True  False   True  True
New Jersey       True     True   False  False  False  True
Connecticut      True     True    True   True   True  True
>>> winter_summer.isna()
             February  January  August  March   June   July
New York        False    False   False   True  False  False
New Jersey      False    False    True   True   True  False
Connecticut     False    False   False  False  False  False



#READ CSV

DRINKS_URL = "https://raw.githubusercontent.com/justmarkham/pandas-videos/master/data/drinks.csv"
#more here: https://github.com/justmarkham/pandas-videos
#Data School 
drinks_df = pd.read_csv(DRINKS_URL)


#REINDEXING THE ROWS USING A COLUMN

#considering using "country" as the index? want to know if there are duplicatED values
>>> drinks_df["country"].duplicated(keep = 'first').any()

#set the index to be one of the columns
drinks_df.set_index("country", inplace = True)
>>> drinks_df.index
Index([u'Afghanistan', u'Albania', u'Algeria', u'Andorra', u'Angola',
       u'Antigua & Barbuda', u'Argentina', u'Armenia', u'Australia',
       u'Austria',
       ...
       u'Tanzania', u'USA', u'Uruguay', u'Uzbekistan', u'Vanuatu',
       u'Venezuela', u'Vietnam', u'Yemen', u'Zambia', u'Zimbabwe'],
      dtype='object', name=u'country', length=193)
#and it drops the column "country" in the process

or 

>>> drinks_df = pd.read_csv(DRINKS_URL)
>>> drinks_df.index = drinks_df["country"]
#this doesn't automatically drop the column


#BASIC METRICS / EXPLORING

drinks_df.info()                             # information about the raw date

drinks_df.describe()                         # gives basic statistics for numerical columns

drinks_df.describe(include = ['object'])     # gives basic counts for object type columns

drinks_df.hist(bins=50, figsize=(20,15) )    # plots histograms for numerical 

#don't look for duplicates in a series, look for duplicatED VALUES
>>> drinks_df["continent"].duplicated( keep = 'first')
#first occurence of any value will be False, other values will be True
>>> drinks_df["continent"].duplicated().any()#returns True if there is even a single duplicated value
True
>>> drinks_df["continent"].nunique()
6
>>> drinks_df.nunique()
country                         193
beer_servings                   130
spirit_servings                 109
wine_servings                    79
total_litres_of_pure_alcohol     90
continent                         6
dtype: int64
>>> drinks_df["continent"].duplicated(keep = 'first').sum()
187
#works with index also
drinks_df.index.duplicated().any()


# DATA TYPES & TYPE CONVERSIONS

>>> drinks_df.dtypes
country                          object         #same as "string"
beer_servings                     int64         #integer
spirit_servings                   int64
wine_servings                     int64
total_litres_of_pure_alcohol    float64
continent                        object
dtype: object

>>> drinks_df["beer_servings"].dtypes           # don't you love this? both dtype and dtypes works here
dtype('float64')
>>> drinks_df["beer_servings"].dtype            # but not in other places in pandas like 
dtype('float64')


>>> drinks_df["beer_servings"] = drinks_df["beer_servings"].astype('float')        # conversion
#remember to assign it or to use inplace = True 
#seems to work for 'float' and float
>>> drinks_df.dtypes
country                          object
beer_servings                   float64         #now it's floats
spirit_servings                   int64
wine_servings                     int64
total_litres_of_pure_alcohol    float64
continent                        object
dtype: object

>>> drinks_df["beer_servings"] = drinks_df["beer_servings"].astype('int', inplace=True)
#works for 'int' and int
>>> drinks_df.dtypes
country                          object
beer_servings                     int64         #now it is integers ahgain
spirit_servings                   int64
wine_servings                     int64
total_litres_of_pure_alcohol    float64
continent                        object
dtype: object

>>> del drinks_df       #start fresh, to tell it which column to use for index, and conversions
>>> drinks_df = pd.read_csv(DRINKS_URL, index_col = 0, dtype = { 'beer_servings' : float})
#notice: it's not index = "country", or set_index = "country", 
#notice: it's not dtypes as in drinks_df.dtypes; it is dtype <- confirmed
#notice: float or 'float'
>>> drinks_df.head()
             beer_servings  spirit_servings  wine_servings  total_litres_of_pure_alcohol continent
country                                                                                           
Afghanistan            0.0                0              0                           0.0      Asia
Albania               89.0              132             54                           4.9    Europe
Algeria               25.0                0             14                           0.7    Africa
Andorra              245.0              138            312                          12.4    Europe
Angola               217.0               57             45                           5.9    Africa


>>> chipotle_df = pd.read_table("http://bit.ly/chiporders")
>>> chipotle_df.head()
   order_id  quantity    ...                                     choice_description item_price
0         1         1    ...                                                    NaN     $2.39 
1         1         1    ...                                           [Clementine]     $3.39 
2         1         1    ...                                                [Apple]     $3.39 
3         1         1    ...                                                    NaN     $2.39 
4         2         2    ...      [Tomatillo-Red Chili Salsa (Hot), [Black Beans...    $16.98 

>>> chipotle_df["item_price"].str.lstrip("$").astype(float).mean()
7.464335785374397
#for that column use the 'StringMethods' object, left-strip the $, convert to type float, and take the mean.
#notice float but works with 'float'

chipotle_df["item_name"].str.contains("Chicken")
#this works, it produces a long series of True/False
chipotle_df["item_name"].str.contains("Chicken").astype(int)
#same but now it is 0,1


# GROUPBY

>>> drinks_df.groupby( by = [ "continent" ] )["beer_servings"].mean()
continent
Africa            61.471698
Asia              37.045455
Europe           193.777778
North America    145.434783
Oceania           89.687500
South America    175.083333
Name: beer_servings, dtype: float64

>>> drinks_df.groupby( by = [ "continent", "country" ] )["beer_servings"].mean()
#in this case the mean doesn't do much because there are no more than one
#observations (rows) for any country, so there's nothing to average
#or, it's an average of one.
continent      country                 
Africa         Algeria                      25
               Angola                      217
               Benin                        34
               Botswana                    173

                                          ... 
North America  Trinidad & Tobago           197
               USA                         249
Oceania        Australia                   261
               Cook Islands                  0
               Fiji                         77
                                          ... 


#OUTPUT A DATAFRAME

>>> print(a_df[ cols_to_keep ].to_string(index=False) )
prints the dataframe without index but with leading space.
       Date   Amount
 05/01/2021  -$12.00
 04/01/2021   -$7.75

>>> a_df[[ cols_to_keep ]].to_clipboard(index=False) 
removes the spaces, but doesn't align the decimal point. Can be pasted into excel however.


#OTHER SOURCES
https://www.youtube.com/watch?v=2AFGPdNn4FM
  for why the following makes sense:
df[df.somecol >= 200]
  or
new_df = df[df.somecol >= 200]
   
https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf
consider
https://s3.amazonaws.com/assets.datacamp.com/blog_assets/PandasPythonForDataScience.pdf
https://medium.com/dunder-data/minimally-sufficient-pandas-cheat-sheet-34f3a6888c36
https://www.machinelearningplus.com/python/101-pandas-exercises-python/


